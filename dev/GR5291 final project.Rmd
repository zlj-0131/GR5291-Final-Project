---
title: "G5291 Final PROJECT"
author: "Lingjia Zhang"
date: "10/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Exploratory Data Analysis







#### Feature Selection

```{r}
# Load libraries
library(tidyr)
library(tidyverse)
library(dplyr)
library(mlbench)
library(ggplot2)
library(randomForest)
library(caret)
library(reshape2)

# Load the dataset
df <- read.csv("../data/NFWBS_PUF_2016_data.csv")
head(df)

```

```{r}

# Show dimension of the dataframe 
dim(df)

# Set PUF_ID as index
df <- df %>%
  remove_rownames %>% 
  column_to_rownames(var="PUF_ID")

# notice that negative values are invalid entries, 
# so replacing them with NA
for (i in 1:nrow(df)){
  for (j in 1:ncol(df)){
    if (df[i,j] < 0){
      df[i,j] = NA
    }
  }
}
```

```{r eval=FALSE, include=FALSE, echo=FALSE, message=FALSE}
# number of na values in row and column
nacol = colSums(is.na(df))
mean(nacol); sd(nacol)

narow = rowSums(is.na(df))
mean(narow); sd(narow)
```

```{r}
# use knn impute to resolve NA problem
df = knn.impute(as.matrix(df)) %>% 
  as.data.frame()

head(df)

# Check NA values
colSums(is.na(df))

df <- df %>%
  mutate(HEALTH = ifelse(HEALTH == -1 | HEALTH == 1 | HEALTH == 2, 0, 1))

```

```{r}

sapply(df, class)

```

## Feature Importance Method

```{r}

# Fit random forest to the dataset
fit <- randomForest(HEALTH~., data=df)

```

```{r}
# Show the variable importance table
vi <- varImp(fit, scale = FALSE)
vi <- rownames_to_column(vi, "features")
vi[order(-vi$Overall),]

# Plot the variable importance
varImpPlot(fit,type=2)

```

```{r}

# Determine 20 most importanct features
selected_features <- vi$features[1:20]

# Generate new dataset
column_keep <- c("HEALTH", selected_features)
new_df <- df[column_keep]

head(new_df)

# Export to csv
write.csv(new_df,"../data/Feature_selection_data.csv", row.names = FALSE)

```

## Correlation matrix

```{r}

# calculate correlation matrix
correlationMatrix <- cor(new_df)

# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)

# print indexes of highly correlated attributes
print(highlyCorrelated)

cormat <- round(correlationMatrix,2)

# reorder the correlation matrix helper function
reorder_cormat <- function(cormat){
  # Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <- cormat[hc$order, hc$order]
}

# Get lower triangle of the correlation matrix
  get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
# Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
upper_tri <- get_upper_tri(cormat)

# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)

# Construct a heatmap of the dataset
text_size = 2
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
  geom_text(aes(label = round(value, 1)), size = text_size) + 
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),
    text = element_text(size = text_size * (5))) +
 coord_fixed()
# Print the heatmap
print(ggheatmap)

```

```{r}

library(lares)

corr_cross(new_df, # name of dataset
  max_pvalue = 0.05, # display only significant correlations (at 5% level)
  top = 10 # display top 10 couples of variables (by correlation coefficient)
)

```

```{r}

library(Information)
library(gridExtra)

### Ranking variables using penalized IV  
IV <- create_infotables(data = new_df, y = "HEALTH", bins=10, parallel=TRUE)

IV_Value = data.frame(IV$Summary)

IV_Value

```

```{r}

new_df <- subset(new_df, select = -c(FS1_1, FWB2_1, FWB1_3))

dim(new_df)

```

```{r}

# Export to csv
write.csv(new_df, "../data/Feature_selection_data.csv", row.names = FALSE)

```

```{r}

# Imbalance Data

new_df <- new_df %>% 
  mutate(HEALTH = as.factor(HEALTH))

as.data.frame(table(new_df$HEALTH))

ggplot(new_df , aes(x = factor(HEALTH), fill = factor(HEALTH))) +  
  geom_bar() + 
  xlab("Healthy OR Not") +
  labs(fill="Healthy OR Not")

```


```{r}
new_df <- new_df %>% 
  mutate(HEALTH = as.factor(HEALTH))

# SMOTE : : Synthetic Minority Oversampling Technique To Handle Class Imbalancy In Binary Classification
library(DMwR)

balanced_df <- SMOTE(HEALTH~., new_df, perc.over = 500, perc.under = 115, k = 5)
as.data.frame(table(balanced_df$HEALTH))

ggplot(balanced_df , aes(x = factor(HEALTH), fill = factor(HEALTH))) +  
  geom_bar() + 
  xlab("Healthy OR Not") +
  labs(fill="Healthy OR Not")

```

```{r}
# Export to csv
write.csv(balanced_df, "../data/balance_data.csv", row.names = FALSE)

```










